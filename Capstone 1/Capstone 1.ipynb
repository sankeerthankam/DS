{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>EDA on Bank Marketing Dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>https://archive.ics.uci.edu/ml/datasets/Bank+Marketing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forests with untransformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jupyter Notebook with Matplotlib Inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height has been deprecated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the csv file.\n",
    "df_test = pd.read_csv(\"data/cleaned/test.csv\")\n",
    "df_train = pd.read_csv(\"data/cleaned/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenated data\n",
    "df_full = pd.concat([df_test, df_train], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verifying if the data has been contacted by verifying the number of rows\n",
    "print((len(df_test) + len(df_train)) == len(df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job' 'marital' 'education' 'default' 'housing' 'personal' 'contact_type'\n",
      " 'month' 'day' 'poutcome' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(df_full.select_dtypes(include=['O']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical =['job', 'marital', 'education', 'default', 'housing', 'personal', 'contact_type',\n",
    " 'month', 'day', 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dataframes = [df_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dummies for all_dataframes_1 with categorical_fields_1\n",
    "df_full = pd.get_dummies(df_full, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dataframes = [pd.get_dummies(df, columns = categorical) for df in all_dataframes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.912357368293\n",
      "Precision --  0.445974576271\n",
      "Recall --  0.679032258065\n",
      "F1 Score --  0.538363171355\n",
      "AUC --  51838.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf_df_full = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf_df_full.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf_df_full.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95      7618\n",
      "          1       0.45      0.68      0.54       620\n",
      "\n",
      "avg / total       0.93      0.91      0.92      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_split': 1e-07,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 10,\n",
      " 'n_jobs': 1,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [1, 2, 3, 4, 5, 10, 25, 50, 75, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt', 0.2],\n",
      " 'min_samples_leaf': [1, 2, 4, 5, 10, 50, 100, 200, 500],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 200, 400, 600, 800, 1000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100, 200, 400, 600, 800, 1000]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 0.2]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [1, 2, 3, 4, 5, 10, 25, 50, 75, 100, 110, None]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 5, 10, 50, 100, 200, 500]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 22.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200, 400, 600, 800, 1000], 'max_features': ['auto', 'sqrt', 0.2], 'max_depth': [1, 2, 3, 4, 5, 10, 25, 50, 75, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4, 5, 10, 50, 100, 200, 500], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 0.2,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 800}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate Random Search: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = ', accuracy_score(pred, y_test)*100)\n",
    "    return (accuracy_score(pred, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1779 degrees.\n",
      "Accuracy =  88.0387931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishu\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Nishu\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train.values.ravel())\n",
    "base_accuracy = evaluate(base_model, X_test, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1866 degrees.\n",
      "Accuracy =  88.0387931034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishu\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_acc = evaluate(best_random, X_test, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dummies for all_dataframes_1 with categorical_fields_1\n",
    "df_full = pd.get_dummies(df_full, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.916484583637\n",
      "Precision --  0.503177966102\n",
      "Recall --  0.684438040346\n",
      "F1 Score --  0.579975579976\n",
      "AUC --  56956.5\n"
     ]
    }
   ],
   "source": [
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "df_full_best_model = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "df_full_best_model.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = df_full_best_model.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.912357368293\n",
      "Precision --  0.445974576271\n",
      "Recall --  0.679032258065\n",
      "F1 Score --  0.538363171355\n",
      "AUC --  51838.5\n"
     ]
    }
   ],
   "source": [
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "df_full_base_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "df_full_base_model.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = df_full_base_model.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 0.00%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_acc - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4],\n",
    "    'min_samples_split': [8, 10],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 18.0min finished\n",
      "C:\\Users\\Nishu\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_estimator.fit(X, y, **self.fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.906652100024\n",
      "Precision --  0.273305084746\n",
      "Recall --  0.756598240469\n",
      "F1 Score --  0.401556420233\n",
      "AUC --  32250.5\n"
     ]
    }
   ],
   "source": [
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Params of best model in Grid search\n",
    "df_full_best_model = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "df_full_best_model.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = df_full_best_model.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search Base Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.908351541636\n",
      "Precision --  0.404661016949\n",
      "Recall --  0.664347826087\n",
      "F1 Score --  0.502962475313\n",
      "AUC --  46974.0\n"
     ]
    }
   ],
   "source": [
    "X = df_full.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_full[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Params of base model in Random search\n",
    "df_full_best_model = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "df_full_best_model.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = df_full_best_model.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.1337 degrees.\n",
      "Accuracy =  91.2357368293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishu\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 0.00%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "** Note: ** Since the goal of this project is to minimize False Negatives (How many did we miss), we focus on getting a recall value close to 100% with a less bad precision value\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After builds models with various transformations, feature engineering techniques and their combinations, here are that were selected based on recall, precision and f1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/models and scores.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Note: ** <br>\n",
    "Primary Models - Highlighted in yellow <br>\n",
    "Experimenting Models - Highlighted in blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Hence, proceeding with models builts for the above dataframes. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Transformations and Random Forests on the transformed datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1 Data Transformation\n",
    "\n",
    "**Consolidating and Categorizing:**\n",
    "\n",
    "    a. 'job', 'education' and 'month' -- Consolidating these variables on percentage of positive and negative responses.\n",
    "    b. 'age' -- Binning and Categorizing the ages into a 'young_adult', 'adult' and 'senior' using 'qcut'. \n",
    "    c. 'day' -- Categorizing day into 'weekday_1', 'weekday_2' and 'weekend' categories.\n",
    "    \n",
    "**Merging two features:**\n",
    "\n",
    "    a. 'age' and 'marital' -- Merging two variable to create a new.\n",
    "\n",
    "**Dropping a column:** \n",
    "\n",
    "    a. 'duration' -- Create two dataframes (one with 'duration' column and another without). This is covered at the end of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the csv file.\n",
    "df_test = pd.read_csv(\"data/cleaned/test.csv\")\n",
    "df_train = pd.read_csv(\"data/cleaned/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenated data\n",
    "df_full = pd.concat([df_test, df_train], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transformation 1: Categorizing `job`, `education` and `month`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transformations = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to categorize 'job', 'education' and 'month'\n",
    "def transformation_1(df):\n",
    "\n",
    "    col = ['job', 'education', 'month']\n",
    "\n",
    "    for c in col:\n",
    "        if c == 'job':\n",
    "            df['job'].replace(['blue-collar', 'services', 'entrepreneur', 'housemaid', 'self-employed', 'technician', \n",
    "                  'management', 'unknown', 'admin.', 'unemployed', 'retired', 'student'],\n",
    "                   ['jl4', 'jl4', 'jl4', 'jl3', 'jl3', 'jl3', 'jl3', 'jl2', 'jl2', 'jl2', 'jl1', 'jl1'], \n",
    "                   inplace=True)\n",
    "\n",
    "        elif c == 'education':\n",
    "            df['education'].replace(['basic.9y','basic.6y','basic.4y','high.school','professional.course','university.degree','unknown','illiterate'],\n",
    "                      ['el4','el4','el3','el3','el3','el2','el2','el1'], \n",
    "                      inplace=True)\n",
    "\n",
    "        elif c == 'month':\n",
    "            df['month'].replace(['may','jul','nov','aug','jun','apr','oct','sep','dec','mar'],['ml3','ml3','ml3','ml3','ml3','ml2','ml1','ml1','ml1','ml1'], \n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transformation 2: Categorizing `age`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to categorize 'age'\n",
    "def transformation_2(df):\n",
    "    age_groups = ['young_adult', 'adult', 'senior']\n",
    "    df['age_group'] = pd.qcut(df['age'], 3, labels = age_groups)\n",
    "    df['age_group'] = pd.Categorical(df.age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transformation 3 - Categorizing 'day' variable **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to categorize 'day'\n",
    "def transformation_3(df):\n",
    "    df['day'].replace(['sum', 'sat', 'mon', 'tue', 'wed', 'thu', 'fri'],\n",
    "                      ['weekend', 'weekend', 'weekday_1', 'weekday_1', 'weekday_1', 'weekday_2', 'weekday_2'], \n",
    "                      inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transformation 4: Merging `marital` and `age`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>age</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>98</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>divorced</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>67</td>\n",
       "      <td>93</td>\n",
       "      <td>141</td>\n",
       "      <td>129</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>166</td>\n",
       "      <td>153</td>\n",
       "      <td>158</td>\n",
       "      <td>171</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>193</td>\n",
       "      <td>173</td>\n",
       "      <td>114</td>\n",
       "      <td>155</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>144</td>\n",
       "      <td>150</td>\n",
       "      <td>121</td>\n",
       "      <td>132</td>\n",
       "      <td>140</td>\n",
       "      <td>142</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>131</td>\n",
       "      <td>118</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>150</td>\n",
       "      <td>196</td>\n",
       "      <td>252</td>\n",
       "      <td>372</td>\n",
       "      <td>529</td>\n",
       "      <td>758</td>\n",
       "      <td>909</td>\n",
       "      <td>936</td>\n",
       "      <td>1035</td>\n",
       "      <td>1071</td>\n",
       "      <td>1076</td>\n",
       "      <td>1136</td>\n",
       "      <td>914</td>\n",
       "      <td>872</td>\n",
       "      <td>979</td>\n",
       "      <td>777</td>\n",
       "      <td>864</td>\n",
       "      <td>797</td>\n",
       "      <td>783</td>\n",
       "      <td>686</td>\n",
       "      <td>792</td>\n",
       "      <td>762</td>\n",
       "      <td>671</td>\n",
       "      <td>743</td>\n",
       "      <td>615</td>\n",
       "      <td>670</td>\n",
       "      <td>580</td>\n",
       "      <td>584</td>\n",
       "      <td>544</td>\n",
       "      <td>513</td>\n",
       "      <td>487</td>\n",
       "      <td>543</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>357</td>\n",
       "      <td>229</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "      <td>94</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>381</td>\n",
       "      <td>429</td>\n",
       "      <td>489</td>\n",
       "      <td>583</td>\n",
       "      <td>608</td>\n",
       "      <td>852</td>\n",
       "      <td>859</td>\n",
       "      <td>891</td>\n",
       "      <td>776</td>\n",
       "      <td>652</td>\n",
       "      <td>526</td>\n",
       "      <td>514</td>\n",
       "      <td>489</td>\n",
       "      <td>399</td>\n",
       "      <td>362</td>\n",
       "      <td>301</td>\n",
       "      <td>229</td>\n",
       "      <td>220</td>\n",
       "      <td>172</td>\n",
       "      <td>158</td>\n",
       "      <td>170</td>\n",
       "      <td>124</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "age       17  18  19  20  21   22   23   24   25   26   27   28   29   30   31   32    33    34    35    36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   56   57   58   59   60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  91  92  94  95  98\n",
       "marital                                                                                                                                                                                                                                                                                                                                                                    \n",
       "divorced   0   0   0   0   0    0    0    4   17   13   14   21   67   93  141  129   140   141   166   153  158  171  152  154  193  173  114  155  184  157  157  144  150  121  132  140  142  132  124  131  118  100   87   44   5   4   4   4   3   7   5   6   6  11   3   7   8   9   8   4   7  10   0  14   9   6   7   5   3   2   1  18   2   0   1   0   1   0\n",
       "married    0   0   0   1   8   16   30   78  150  196  252  372  529  758  909  936  1035  1071  1076  1136  914  872  979  777  864  797  783  686  792  762  671  743  615  670  580  584  544  513  487  543  468  448  357  229  65  57  51  53  39  43  20  23  28  36  44  25  25  23  16  29  12  17  14  17  11   9  10   2  11   5   0   4   0   2   3   1   0   2\n",
       "single     5  28  42  64  94  121  196  381  429  489  583  608  852  859  891  776   652   526   514   489  399  362  301  229  220  172  158  170  124  110  100   92   70   79   42   52   46   37   35   29   58   25   18   10   3   1   0   0   2   5   1   4   0   0   6   2   1   0   0   1   1   0   0   0   0   2   0   0   1   1   0   0   0   0   0   0   0   0\n",
       "unknown    0   0   0   0   0    0    0    0    2    0    2    0    5    4    6    5     6     7     3     2    4    2    0    1    1    0    0    0    3    1    0    0    4    5    0    3    1    2    2    1    2    3    1    0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_transformations.marital, df_transformations.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to categorize 'marital' and 'age'\n",
    "def transformation_4(df):\n",
    "    df['age_marital'] = df.apply(lambda x: x['age_group'] + ' & ' + x['marital'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Applying transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The transformed data can be further divided into two dataframes:\n",
    "\n",
    "1. df_age_1 - with `age` \n",
    "2. df_age_2 - with `age_group`\n",
    "2. df_age_marital - with `age_marital`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframes to apply transformations\n",
    "df_age_1 = df_full.copy(deep = True)\n",
    "df_age_2 = df_full.copy(deep = True)\n",
    "df_age_marital = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [df_age_1, df_age_2, df_age_marital]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to apply all transformations\n",
    "def transformations(df):\n",
    "    transformation_1(df)\n",
    "    transformation_2(df)\n",
    "    transformation_3(df)\n",
    "    transformation_4(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying transformations to 'df_age_1', 'df_age_2' and 'df_age_marital'\n",
    "for df in dataframes:\n",
    "    transformations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_marital</th>\n",
       "      <th>age_group</th>\n",
       "      <th>day</th>\n",
       "      <th>education</th>\n",
       "      <th>job</th>\n",
       "      <th>month</th>\n",
       "      <th>marital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>adult &amp; married</td>\n",
       "      <td>adult</td>\n",
       "      <td>weekday_1</td>\n",
       "      <td>el4</td>\n",
       "      <td>jl4</td>\n",
       "      <td>ml3</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>senior &amp; married</td>\n",
       "      <td>senior</td>\n",
       "      <td>weekday_1</td>\n",
       "      <td>el3</td>\n",
       "      <td>jl2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>senior &amp; married</td>\n",
       "      <td>senior</td>\n",
       "      <td>weekday_1</td>\n",
       "      <td>el3</td>\n",
       "      <td>jl4</td>\n",
       "      <td>ml3</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>young_adult &amp; married</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>weekday_2</td>\n",
       "      <td>el3</td>\n",
       "      <td>jl2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>adult &amp; married</td>\n",
       "      <td>adult</td>\n",
       "      <td>weekday_2</td>\n",
       "      <td>el2</td>\n",
       "      <td>jl2</td>\n",
       "      <td>ml3</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            age_marital    age_group        day education  job month  marital\n",
       "0   36        adult & married        adult  weekday_1       el4  jl4   ml3  married\n",
       "1   60       senior & married       senior  weekday_1       el3  jl2   ml3  married\n",
       "2   45       senior & married       senior  weekday_1       el3  jl4   ml3  married\n",
       "3   27  young_adult & married  young_adult  weekday_2       el3  jl2   ml3  married\n",
       "4   38        adult & married        adult  weekday_2       el2  jl2   ml3  married"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_age_marital[['age', 'age_marital', 'age_group', 'day', 'education', 'job', 'month', 'marital']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dropping unwanted columns: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job' 'marital' 'education' 'default' 'housing' 'personal' 'contact_type'\n",
      " 'month' 'day' 'poutcome' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(df_transformations.select_dtypes(include=['O']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_1 = ['job', 'marital', 'education', 'default', 'housing', 'personal', 'contact_type',\n",
    " 'month', 'day', 'poutcome']\n",
    "\n",
    "categorical_2 = ['job', 'marital', 'education', 'default', 'housing', 'personal', 'contact_type',\n",
    " 'month', 'day', 'poutcome', 'age_group']\n",
    "\n",
    "categorical_3 = ['job', 'education', 'default', 'housing', 'personal', 'contact_type',\n",
    " 'month', 'day', 'poutcome', 'age_marital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping respective columns \n",
    "df_age_1 = df_age_1.drop(['age_group', 'age_marital'], axis = 1)\n",
    "df_age_2 = df_age_2.drop(['age', 'age_marital'], axis = 1)\n",
    "df_age_marital = df_age_marital.drop(['age', 'age_group', 'marital'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dummies for the dataframes\n",
    "df_age_1 = pd.get_dummies(df_age_1, columns = categorical_1)\n",
    "df_age_2 = pd.get_dummies(df_age_2, columns = categorical_2)\n",
    "df_age_marital = pd.get_dummies(df_age_marital, columns = categorical_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "If the above piece of code does not create dummy variables, use the following code snippet: <br>\n",
    "<br>\n",
    "all_dataframes = [pd.get_dummies(df, columns = categorical) for df in all_dataframes]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest on `df_age_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915513474144\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95      7558\n",
      "          1       0.49      0.68      0.57       680\n",
      "\n",
      "avg / total       0.93      0.92      0.92      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.907259043457\n",
      "Precision --  0.407838983051\n",
      "Recall --  0.652542372881\n",
      "F1 Score --  0.501955671447\n",
      "AUC --  47360.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.917212915756\n",
      "Precision --  0.512711864407\n",
      "Recall --  0.685552407932\n",
      "F1 Score --  0.586666666667\n",
      "AUC --  58362.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.909079873756\n",
      "Precision --  0.323093220339\n",
      "Recall --  0.734939759036\n",
      "F1 Score --  0.448859455482\n",
      "AUC --  37883.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest on `df_age_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.914299587278\n",
      "Precision --  0.491525423729\n",
      "Recall --  0.672463768116\n",
      "F1 Score --  0.567931456548\n",
      "AUC --  56701.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95      7548\n",
      "          1       0.49      0.67      0.57       690\n",
      "\n",
      "avg / total       0.93      0.91      0.92      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.908108764263\n",
      "Precision --  0.423728813559\n",
      "Recall --  0.652528548124\n",
      "F1 Score --  0.513808606294\n",
      "AUC --  48131.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.91709152707\n",
      "Precision --  0.507415254237\n",
      "Recall --  0.687230989957\n",
      "F1 Score --  0.583790371725\n",
      "AUC --  57850.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.908837096383\n",
      "Precision --  0.301906779661\n",
      "Recall --  0.755968169761\n",
      "F1 Score --  0.431491294474\n",
      "AUC --  35069.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_age_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_age_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace outliers with Upper and Lower bounds for 'duration' and 'employee' column\n",
    "def outliers_bounds(df):\n",
    "    df['duration'] = df['duration'].apply(lambda x: int(math.floor(x / 10.0)) * 10 if(x%10<5) else int(math.ceil(x / 10.0)) * 10 )\n",
    "    df['employees'] = df['employees'].apply(lambda x: int(math.floor(x / 10.0)) * 10 if(x%10<5) else int(math.ceil(x / 10.0)) * 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace outliers with Replace outliers with upper and lower quartiles (`percentiles`)\n",
    "def outliers_quartiles(df):\n",
    "    colz = ['duration', 'dcontacts', 'pdays', 'evr', 'cpi', 'cci', 'euribor', 'employees']\n",
    "    uq = 0.95\n",
    "    lq = 0.05\n",
    "    for col in colz:\n",
    "        df[col] = df[col].clip_upper(int(df[col].quantile(uq)))\n",
    "        df[col] = df[col].clip_lower(int(df[col].quantile(lq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace outliers with Apply Logarithmic transformations (Not just to the outliers but to all the samples (observations) in the numeric columns). \n",
    "def outliers_log(df):\n",
    "    num = ['age','dcontacts', 'cpi', 'euribor','employees']\n",
    "    for n in num:\n",
    "        df[n] = np.log(df[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Applying Outlier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The transformed data can be further divided into two dataframes:\n",
    "\n",
    "1. df_outliers_1 - outluiers treatment \n",
    "2. df_outliers_2 - outliers and transformations\n",
    "2. df_outliers_3 - outliers, transformations and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform outlier treatment\n",
    "def outliers(df):\n",
    "        outliers_bounds(df)\n",
    "        outliers_quartiles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numerical Columns\n",
    "numerical = ['age', 'duration', 'dcontacts', 'pdays', 'pcontacts', 'evr', 'cpi', 'cci', 'euribor', 'employees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform normalization\n",
    "def normalization(df):\n",
    "    for n in numerical:\n",
    "        col = df[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.MinMaxScaler()).fit_transform(col)\n",
    "        # df[n+'_normalized'] = pd.df(col_transformed)\n",
    "        df[n] = pd.DataFrame(col_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform standardization\n",
    "def standardization(df):\n",
    "    for n in numerical:\n",
    "        col = df[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.StandardScaler()).fit_transform(col)\n",
    "        # df[n+'_standardized'] = pd.DataFrame(col_transformed)\n",
    "        df[n] = pd.DataFrame(col_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample(df):\n",
    "\n",
    "    major_class = df[df.y == 'no']\n",
    "    minor_class = df[df.y == 'yes']\n",
    "    \n",
    "    df_minor_upsample = resample(minor_class, replace = True, n_samples = len(major_class), random_state = 42)\n",
    "    df_upsample = pd.concat([major_class, df_minor_upsample])\n",
    "    \n",
    "    return df_upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upsampled\n",
    "df_upsample_1 = df_full.copy(deep = True)\n",
    "\n",
    "# Upsample, Transformations, Oulier Treatment and Logged  \n",
    "df_upsample_4 = df_full.copy(deep = True)\n",
    "\n",
    "# Upsample, Transformations, Oulier Treatment, Logged and Normalized\n",
    "df_upsample_6 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_1 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_1 = upsample(df_upsample_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes    36548\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsample_1.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_1 = pd.get_dummies(df_upsample_1, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.968262653899\n",
      "Precision --  0.999587118084\n",
      "Recall --  0.940315898498\n",
      "F1 Score --  0.969046030687\n",
      "AUC --  434814.0\n"
     ]
    }
   ],
   "source": [
    "X = df_upsample_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_1[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97      6896\n",
      "          1       1.00      0.94      0.97      7724\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.972708618331\n",
      "Precision --  0.998073217726\n",
      "Recall --  0.949587534372\n",
      "F1 Score --  0.973226867074\n",
      "AUC --  439811.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.953283173735\n",
      "Precision --  0.995458298927\n",
      "Recall --  0.917544082202\n",
      "F1 Score --  0.95491451581\n",
      "AUC --  423795.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.939466484268\n",
      "Precision --  0.979906413432\n",
      "Recall --  0.905967680366\n",
      "F1 Score --  0.941487603306\n",
      "AUC --  418177.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_1.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_1[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Upsample, Transformations, Outlier Treatment, Logged and Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_5 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_5 = upsample(df_upsample_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations(df_upsample_5)\n",
    "outliers(df_upsample_5)\n",
    "outliers_log(df_upsample_5)\n",
    "standardization(df_upsample_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_5.drop(['age_group', 'age_marital'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_5 = pd.get_dummies(df_upsample_5, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972503419973\n"
     ]
    }
   ],
   "source": [
    "X = df_upsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_5[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6968\n",
      "          1       1.00      0.95      0.97      7652\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.971545827633\n",
      "Precision --  0.998623726947\n",
      "Recall --  0.947011224223\n",
      "F1 Score --  0.972132904609\n",
      "AUC --  436492.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.950410396717\n",
      "Precision --  0.977016240022\n",
      "Recall --  0.927125506073\n",
      "F1 Score --  0.951417275347\n",
      "AUC --  429567.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.919357045144\n",
      "Precision --  0.934902284613\n",
      "Recall --  0.905854113882\n",
      "F1 Score --  0.920149001016\n",
      "AUC --  421887.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Upsample, Transformations, Outlier Treatment, Logged and Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_6 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_6 = upsample(df_upsample_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations(df_upsample_6)\n",
    "outliers(df_upsample_6)\n",
    "outliers_log(df_upsample_6)\n",
    "normalization(df_upsample_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_upsample_6.drop(['age_group', 'age_marital'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.97243502052\n",
      "Precision --  0.998898981558\n",
      "Recall --  0.948386253757\n",
      "F1 Score --  0.972987465648\n",
      "AUC --  437640.5\n"
     ]
    }
   ],
   "source": [
    "X = df_upsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_6[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      6967\n",
      "          1       1.00      0.95      0.97      7653\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.971614227086\n",
      "Precision --  0.998623726947\n",
      "Recall --  0.947134838794\n",
      "F1 Score --  0.972198030415\n",
      "AUC --  436747.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.95047879617\n",
      "Precision --  0.977016240022\n",
      "Recall --  0.927246603971\n",
      "F1 Score --  0.951481034714\n",
      "AUC --  429695.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.919288645691\n",
      "Precision --  0.934902284613\n",
      "Recall --  0.905733333333\n",
      "F1 Score --  0.920086685629\n",
      "AUC --  421760.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_upsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_upsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    major_class = df[df.y == 'no']\n",
    "    minor_class = df[df.y == 'yes']\n",
    "    \n",
    "    df_major_downsample = resample(major_class, replace = False, n_samples = len(minor_class), random_state = 42)\n",
    "    df_downsample = pd.concat([df_major_downsample, minor_class])\n",
    "\n",
    "    return df_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsample, Transformations\n",
    "df_downsample_2 = df_full.copy(deep = True)\n",
    "\n",
    "# Downsample, Transformations, Oulier Treatment, Logged and Standardized\n",
    "df_downsample_5 = df_full.copy(deep = True)\n",
    "\n",
    "# Downsample, Transformations, Oulier Treatment, Logged and Normalized\n",
    "df_downsample_6 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Downsample and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_2 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_2 = downsample(df_downsample_2)\n",
    "transformations(df_downsample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_2.drop(['age_group', 'age_marital'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_downsample_2 = pd.get_dummies(df_downsample_2, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883620689655\n"
     ]
    }
   ],
   "source": [
    "X = df_downsample_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_2[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.88       836\n",
      "          1       0.93      0.86      0.89      1020\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.853448275862\n",
      "Precision --  0.86093418259\n",
      "Recall --  0.851890756303\n",
      "F1 Score --  0.856388595565\n",
      "AUC --  52485.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.889547413793\n",
      "Precision --  0.943736730361\n",
      "Recall --  0.853986551393\n",
      "F1 Score --  0.896621280888\n",
      "AUC --  52224.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.880387931034\n",
      "Precision --  0.936305732484\n",
      "Recall --  0.844827586207\n",
      "F1 Score --  0.888217522659\n",
      "AUC --  50692.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_2.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_2[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Downsample, Transformations, Outlier Treatment, Logged and Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_5 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_5 = downsample(df_downsample_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform standardization\n",
    "def standardization_new(df):\n",
    "    for n in numerical:\n",
    "        col = df[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.StandardScaler()).fit_transform(col)\n",
    "        # df[n+'_standardized'] = pd.DataFrame(col_transformed)\n",
    "        df[n] = col_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations(df_downsample_5)\n",
    "outliers(df_downsample_5)\n",
    "outliers_log(df_downsample_5)\n",
    "standardization_new(df_downsample_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_5.drop(['age_group', 'age_marital'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_5 = pd.get_dummies(df_downsample_5, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880387931034\n"
     ]
    }
   ],
   "source": [
    "X = df_downsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_5[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87       836\n",
      "          1       0.92      0.85      0.89      1020\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.852370689655\n",
      "Precision --  0.867303609342\n",
      "Recall --  0.845755693582\n",
      "F1 Score --  0.856394129979\n",
      "AUC --  52605.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.885775862069\n",
      "Precision --  0.934182590234\n",
      "Recall --  0.854368932039\n",
      "F1 Score --  0.892494929006\n",
      "AUC --  52738.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.875538793103\n",
      "Precision --  0.918259023355\n",
      "Recall --  0.848871442591\n",
      "F1 Score --  0.882202957675\n",
      "AUC --  51842.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_5.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_5[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Downsample, Transformations, Outlier Treatment, Logged and Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_6 = df_full.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_6 = downsample(df_downsample_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform normalization\n",
    "def normalization_new(df):\n",
    "    for n in numerical:\n",
    "        col = df[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.MinMaxScaler()).fit_transform(col)\n",
    "        # df[n+'_normalized'] = pd.df(col_transformed)\n",
    "        df[n] = col_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations(df_downsample_6)\n",
    "outliers(df_downsample_6)\n",
    "outliers_log(df_downsample_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalization_new(df_downsample_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_6.drop(['age_group', 'age_marital'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsample_6 = pd.get_dummies(df_downsample_6, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880387931034\n"
     ]
    }
   ],
   "source": [
    "X = df_downsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_6[['y']], drop_first = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87       836\n",
      "          1       0.92      0.85      0.89      1020\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Base Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.852370689655\n",
      "Precision --  0.867303609342\n",
      "Recall --  0.845755693582\n",
      "F1 Score --  0.856394129979\n",
      "AUC --  52605.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Random Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.885775862069\n",
      "Precision --  0.934182590234\n",
      "Recall --  0.854368932039\n",
      "F1 Score --  0.892494929006\n",
      "AUC --  52738.0\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    " max_features = 0.2,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 5,\n",
    " n_estimators = 800, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Grid Search - Best Params **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.875538793103\n",
      "Precision --  0.918259023355\n",
      "Recall --  0.848871442591\n",
      "F1 Score --  0.882202957675\n",
      "AUC --  51842.5\n"
     ]
    }
   ],
   "source": [
    "# Train and Test data\n",
    "X = df_downsample_6.drop(['y'], axis = 1)\n",
    "y = pd.get_dummies(df_downsample_6[['y']], drop_first = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "data = [X_train, X_test, y_train, y_test]\n",
    "for d in data:\n",
    "    d = np.array(d)\n",
    "    \n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    " max_features = 3,\n",
    " min_samples_leaf = 5,\n",
    " min_samples_split = 8,\n",
    " n_estimators = 100, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "# Predict test data\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "# Accuray Score\n",
    "print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "print(\"AUC -- \", metrics.auc(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After builds models with various transformations, feature engineering techniques and their combinations, here are that were selected based on recall, precision and f1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/models and scores.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Note: ** <br>\n",
    "Primary Models - Highlighted in yellow <br>\n",
    "Experimenting Models - Highlighted in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Applying Best Params from Random Search and Grid Search using a for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dfs = [df_full, df_age_1, df_age_2, df_upsample_1, df_upsample_5, df_upsample_6, df_downsample_2, df_downsample_5, df_downsample_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.908351541636\n",
      "Precision --  0.404661016949\n",
      "Recall --  0.664347826087\n",
      "F1 Score --  0.502962475313\n",
      "AUC --  46974.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.907259043457\n",
      "Precision --  0.407838983051\n",
      "Recall --  0.652542372881\n",
      "F1 Score --  0.501955671447\n",
      "AUC --  47360.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.908108764263\n",
      "Precision --  0.423728813559\n",
      "Recall --  0.652528548124\n",
      "F1 Score --  0.513808606294\n",
      "AUC --  48131.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.972708618331\n",
      "Precision --  0.998073217726\n",
      "Recall --  0.949587534372\n",
      "F1 Score --  0.973226867074\n",
      "AUC --  439811.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.971545827633\n",
      "Precision --  0.998623726947\n",
      "Recall --  0.947011224223\n",
      "F1 Score --  0.972132904609\n",
      "AUC --  436492.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.971614227086\n",
      "Precision --  0.998623726947\n",
      "Recall --  0.947134838794\n",
      "F1 Score --  0.972198030415\n",
      "AUC --  436747.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.853448275862\n",
      "Precision --  0.86093418259\n",
      "Recall --  0.851890756303\n",
      "F1 Score --  0.856388595565\n",
      "AUC --  52485.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.852370689655\n",
      "Precision --  0.867303609342\n",
      "Recall --  0.845755693582\n",
      "F1 Score --  0.856394129979\n",
      "AUC --  52605.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.852370689655\n",
      "Precision --  0.867303609342\n",
      "Recall --  0.845755693582\n",
      "F1 Score --  0.856394129979\n",
      "AUC --  52605.5\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Random Search\n",
    "for df in all_dfs:\n",
    "    # Train and Test data\n",
    "    X = df.drop(['y'], axis = 1)\n",
    "    y = pd.get_dummies(df[['y']], drop_first = True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # Converting dataframe to numpy array\n",
    "    data = [X_train, X_test, y_train, y_test]\n",
    "    for d in data:\n",
    "        d = np.array(d)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "    # Predict test data\n",
    "    pred = rf.predict(X_test)\n",
    "\n",
    "    # Accuray Score\n",
    "    print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "    print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "    print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "    print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "    print(\"AUC -- \", metrics.auc(pred, y_test))\n",
    "    print(\"----------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>dcontacts</th>\n",
       "      <th>pdays</th>\n",
       "      <th>pcontacts</th>\n",
       "      <th>evr</th>\n",
       "      <th>cpi</th>\n",
       "      <th>cci</th>\n",
       "      <th>euribor</th>\n",
       "      <th>employees</th>\n",
       "      <th>y</th>\n",
       "      <th>job_jl1</th>\n",
       "      <th>job_jl2</th>\n",
       "      <th>job_jl3</th>\n",
       "      <th>job_jl4</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>education_el1</th>\n",
       "      <th>education_el2</th>\n",
       "      <th>education_el3</th>\n",
       "      <th>education_el4</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_unknown</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>personal_no</th>\n",
       "      <th>personal_unknown</th>\n",
       "      <th>personal_yes</th>\n",
       "      <th>contact_type_cellular</th>\n",
       "      <th>contact_type_telephone</th>\n",
       "      <th>month_ml1</th>\n",
       "      <th>month_ml2</th>\n",
       "      <th>month_ml3</th>\n",
       "      <th>day_weekday_1</th>\n",
       "      <th>day_weekday_2</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>0.568246</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996697</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836562</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>0.264092</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954837</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24121</th>\n",
       "      <td>0.659779</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692998</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26957</th>\n",
       "      <td>0.378646</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27762</th>\n",
       "      <td>0.412235</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996697</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836562</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  duration  dcontacts  pdays  pcontacts  evr       cpi       cci  euribor  employees   y  job_jl1  job_jl2  job_jl3  job_jl4  marital_divorced  marital_married  marital_single  marital_unknown  education_el1  education_el2  education_el3  education_el4  default_no  default_unknown  housing_no  housing_unknown  housing_yes  personal_no  personal_unknown  personal_yes  contact_type_cellular  contact_type_telephone  month_ml1  month_ml2  month_ml3  day_weekday_1  day_weekday_2  poutcome_failure  poutcome_nonexistent  poutcome_success\n",
       "4532   0.568246  0.375000   0.000000    1.0        0.0  1.0  0.996697  0.623529      1.0   0.836562  no        0        0        0        1                 0                1               0                0              0              0              0              1           0                1           0                0            1            0                 0             1                      0                       1          0          0          1              1              0                 0                     1                 0\n",
       "7208   0.264092  0.019231   0.000000    1.0        0.0  1.0  0.954837  0.252941      1.0   1.000000  no        0        1        0        0                 0                1               0                0              0              0              0              1           0                1           1                0            0            1                 0             0                      1                       0          0          0          1              1              0                 0                     1                 0\n",
       "24121  0.659779  0.096154   0.000000    1.0        0.0  1.0  0.692998  0.641176      1.0   1.000000  no        0        0        0        1                 0                1               0                0              0              0              1              0           1                0           0                0            1            1                 0             0                      1                       0          0          0          1              1              0                 0                     1                 0\n",
       "26957  0.378646  0.096154   0.386853    1.0        0.0  1.0  1.000000  0.305882      1.0   1.000000  no        0        0        1        0                 0                1               0                0              0              0              1              0           1                0           0                1            0            0                 1             0                      0                       1          0          0          1              1              0                 0                     1                 0\n",
       "27762  0.412235  0.278846   0.386853    1.0        0.0  1.0  0.996697  0.623529      1.0   0.836562  no        0        0        0        1                 0                1               0                0              0              0              0              1           1                0           1                0            0            1                 0             0                      0                       1          0          0          1              1              0                 0                     1                 0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsample_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.916484583637\n",
      "Precision --  0.503177966102\n",
      "Recall --  0.684438040346\n",
      "F1 Score --  0.579975579976\n",
      "AUC --  56956.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.917212915756\n",
      "Precision --  0.512711864407\n",
      "Recall --  0.685552407932\n",
      "F1 Score --  0.586666666667\n",
      "AUC --  58362.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.91709152707\n",
      "Precision --  0.507415254237\n",
      "Recall --  0.687230989957\n",
      "F1 Score --  0.583790371725\n",
      "AUC --  57850.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.953283173735\n",
      "Precision --  0.995458298927\n",
      "Recall --  0.917544082202\n",
      "F1 Score --  0.95491451581\n",
      "AUC --  423795.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.950410396717\n",
      "Precision --  0.977016240022\n",
      "Recall --  0.927125506073\n",
      "F1 Score --  0.951417275347\n",
      "AUC --  429567.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.95047879617\n",
      "Precision --  0.977016240022\n",
      "Recall --  0.927246603971\n",
      "F1 Score --  0.951481034714\n",
      "AUC --  429695.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.889547413793\n",
      "Precision --  0.943736730361\n",
      "Recall --  0.853986551393\n",
      "F1 Score --  0.896621280888\n",
      "AUC --  52224.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.885775862069\n",
      "Precision --  0.934182590234\n",
      "Recall --  0.854368932039\n",
      "F1 Score --  0.892494929006\n",
      "AUC --  52738.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.885775862069\n",
      "Precision --  0.934182590234\n",
      "Recall --  0.854368932039\n",
      "F1 Score --  0.892494929006\n",
      "AUC --  52738.0\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Random Search - Best Params\n",
    "for df in all_dfs:\n",
    "    # Train and Test data\n",
    "    X = df.drop(['y'], axis = 1)\n",
    "    y = pd.get_dummies(df[['y']], drop_first = True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # Converting dataframe to numpy array\n",
    "    data = [X_train, X_test, y_train, y_test]\n",
    "    for d in data:\n",
    "        d = np.array(d)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(bootstrap = False, max_depth = 110,\n",
    "     max_features = 0.2,\n",
    "     min_samples_leaf = 5,\n",
    "     min_samples_split = 5,\n",
    "     n_estimators = 800, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "    # Predict test data\n",
    "    pred = rf.predict(X_test)\n",
    "\n",
    "    # Accuray Score\n",
    "    print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "    print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "    print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "    print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "    print(\"AUC -- \", metrics.auc(pred, y_test))\n",
    "    print(\"----------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy --  0.906652100024\n",
      "Precision --  0.273305084746\n",
      "Recall --  0.756598240469\n",
      "F1 Score --  0.401556420233\n",
      "AUC --  32250.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.909079873756\n",
      "Precision --  0.323093220339\n",
      "Recall --  0.734939759036\n",
      "F1 Score --  0.448859455482\n",
      "AUC --  37883.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.908837096383\n",
      "Precision --  0.301906779661\n",
      "Recall --  0.755968169761\n",
      "F1 Score --  0.431491294474\n",
      "AUC --  35069.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.939466484268\n",
      "Precision --  0.979906413432\n",
      "Recall --  0.905967680366\n",
      "F1 Score --  0.941487603306\n",
      "AUC --  418177.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.919357045144\n",
      "Precision --  0.934902284613\n",
      "Recall --  0.905854113882\n",
      "F1 Score --  0.920149001016\n",
      "AUC --  421887.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.919288645691\n",
      "Precision --  0.934902284613\n",
      "Recall --  0.905733333333\n",
      "F1 Score --  0.920086685629\n",
      "AUC --  421760.0\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.880387931034\n",
      "Precision --  0.936305732484\n",
      "Recall --  0.844827586207\n",
      "F1 Score --  0.888217522659\n",
      "AUC --  50692.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.875538793103\n",
      "Precision --  0.918259023355\n",
      "Recall --  0.848871442591\n",
      "F1 Score --  0.882202957675\n",
      "AUC --  51842.5\n",
      "----------------------------------------------------------------------------------\n",
      "Accuracy --  0.875538793103\n",
      "Precision --  0.918259023355\n",
      "Recall --  0.848871442591\n",
      "F1 Score --  0.882202957675\n",
      "AUC --  51842.5\n",
      "----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Grid Search - Best Params\n",
    "for df in all_dfs:\n",
    "    \n",
    "    # Train and Test data\n",
    "    X = df.drop(['y'], axis = 1)\n",
    "    y = pd.get_dummies(df[['y']], drop_first = True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    # Converting dataframe to numpy array\n",
    "    data = [X_train, X_test, y_train, y_test]\n",
    "    for d in data:\n",
    "        d = np.array(d)\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestClassifier(bootstrap = False, max_depth = 110 ,\n",
    "     max_features = 3,\n",
    "     min_samples_leaf = 5,\n",
    "     min_samples_split = 8,\n",
    "     n_estimators = 100, random_state = 42)\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train.values.ravel());\n",
    "\n",
    "    # Predict test data\n",
    "    pred = rf.predict(X_test)\n",
    "\n",
    "    # Accuray Score\n",
    "    print(\"Accuracy -- \", metrics.accuracy_score(pred, y_test))\n",
    "    print(\"Precision -- \", metrics.precision_score(pred, y_test))\n",
    "    print(\"Recall -- \", metrics.recall_score(pred, y_test))\n",
    "    print(\"F1 Score -- \", metrics.f1_score(pred, y_test))\n",
    "    print(\"AUC -- \", metrics.auc(pred, y_test))\n",
    "    print(\"----------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
