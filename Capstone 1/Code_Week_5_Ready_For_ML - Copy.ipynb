{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataframe ready for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jupyter Notebook with Matplotlib Inline\n",
    "%matplotlib notebook\n",
    "# Import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the cleaned datasets\n",
    "train = pd.read_csv(\"train.csv\", delimiter=',') \n",
    "test = pd.read_csv(\"test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a duplicate dataframe to work on \n",
    "z = train.copy(deep = True)\n",
    "df = train.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Consolidate 'job', 'education' and 'month' variables based on percentage of positive and negative responses.\n",
    "z['job'].replace(['blue-collar', 'services', 'entrepreneur', 'housemaid', 'self-employed', 'technician', \n",
    "                  'management', 'unknown', 'admin.', 'unemployed', 'retired', 'student'],\n",
    "                   ['j1l4', 'j1l4', 'j1l4', 'j1l3', 'j1l3', 'j1l3', 'j1l3', 'j1l2', 'j1l2', 'j1l2', 'j1l1', 'j1l1'], \n",
    "                   inplace=True)\n",
    "\n",
    "z['education'].replace(['basic.9y','basic.6y','basic.4y','high.school','professional.course','university.degree','unknown','illiterate'],\n",
    "                      ['e1l4','e1l4','e1l3','e1l3','e1l3','e1l2','e1l2','e1l1'], \n",
    "                      inplace=True)\n",
    "\n",
    "z['month'].replace(['may','jul','nov','aug','jun','apr','oct','sep','dec','mar'],\n",
    "                      ['m1l3','m1l3','m1l3','m1l3','m1l3','m1l2','m1l1','m1l1','m1l1','m1l1'], \n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Age' Variable\n",
    "Binning the low and high outliers (<23 and >75) into a single bin respectively; and bins of 4 and 5 for values with in 24 and 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single bin[0-20]....bins of 4 [24-60]....bins of 5 [60-75]....single bin [75-100] \n",
    "def final_test(a): \n",
    "    if(a>0 and a<=24):\n",
    "        return \"Cat 1\"\n",
    "    elif (a>24 and a<=31):\n",
    "        return \"Cat 2\"\n",
    "    elif (a>31 and a<=35):\n",
    "        return \"Cat 3\"\n",
    "    elif (a>35 and a<=41):\n",
    "        return \"Cat 4\"\n",
    "    elif (a>41 and a<=49):\n",
    "        return \"Cat 5\"\n",
    "    elif (a>49 and a<=60):\n",
    "        return \"Cat 6\"\n",
    "    elif (a>60 and a<=100):\n",
    "        return \"Cat 7\"\n",
    "\n",
    "z['age_cat'] = z.apply(lambda row: final_test(row['age']), axis=1)\n",
    "df['age_cat'] = df.apply(lambda row: final_test(row['age']), axis=1)\n",
    "# df_duration_bounds['age_cat'] = df_duration_bounds.apply(lambda row: final_test(row['age']), axis=1)\n",
    "# df_employees_bounds['age_cat'] = df_duration_bounds.apply(lambda row: final_test(row['age']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Marital' variable\n",
    "\n",
    "All classes in this variable are similarly distributed.\n",
    "\n",
    "<u>Note:</u>  Come back to this step while using Machine Leanring for variable or feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>divorced</th>\n",
       "      <td>0.893209</td>\n",
       "      <td>0.106791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0.897718</td>\n",
       "      <td>0.102282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>0.859706</td>\n",
       "      <td>0.140294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y               no       yes\n",
       "marital                     \n",
       "divorced  0.893209  0.106791\n",
       "married   0.897718  0.102282\n",
       "single    0.859706  0.140294\n",
       "unknown   0.838710  0.161290"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ..............All categories are almost similarly distributed (83%-90% for NOs)............\n",
    "pd.crosstab(z.marital, z.y, normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Day' variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced day with 'weekday_1', 'weekday_2' and 'weekend' categories.\n",
    "for dataframe in (z, df):\n",
    "    dataframe['day_cat'] = dataframe['day'].copy(deep=True)\n",
    "    dataframe['day_cat'].replace(['sum', 'sat', 'mon', 'tue', 'wed', 'thu', 'fri'],\n",
    "                      ['weekend', 'weekend', 'weekday_1', 'weekday_1', 'weekday_1', 'weekday_2', 'weekday_2'], \n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 'Duration' Variable\n",
    "<u>Important note:</u> this attribute highly affects the output target (e.g., if duration=0 then y='no'). \n",
    "\n",
    "Yet, the duration is not known before a call is performed. \n",
    "Also, after the end of the call y is obviously known. \n",
    "Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "<u> Approach</u>: Create three dataframes, one with 'duration' variable, one without, and one with the variable and upper, lower bounds applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Duplicating with and without 'duration' column\n",
    "df_duration_yes = z.copy(deep = True)\n",
    "df_duration_no = z.copy(deep = True)\n",
    "\n",
    "# # Duplicating and applying 'lower' and 'upper' bounds\n",
    "# df_duration_bounds = z.copy(deep = True)\n",
    "# df_employees_bounds = z.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <u>Notes</u>: del df['column_name']\n",
    " \n",
    " Advantage of drop over del is that drop allows you to drop multiple columns at once, \n",
    " perform the operation inplace or not, and also delete records along any axis (especially useful for a 3-D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # .......................................DROPPPING DURATION COLUMN ......................(IMP)\n",
    "\n",
    "# # deleting duration column \n",
    "# # We are not dropping the column just yet. We will drop the column after the normalization and standardization\n",
    "# df_duration_no.drop('duration',axis=1, inplace=True) #axis = 1 deletes column; axis = 0 delets rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace valid outliers with logarithmic transformation\n",
    "\n",
    "Replace invalid outliers (human-error) with 90th percentile or upper bounds OR exclude the record from the dataframe. \n",
    "\n",
    "IQR - https://www.youtube.com/watch?v=dNHGVLXBTgI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Applying Upper and Lower bounds to 'duration' and 'employees' variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upper and Lower bounds for 'duration' column\n",
    "z['duration'] = z['duration'].apply(lambda x: int(math.floor(x / 10.0)) * 10 if(x%10<5) else int(math.ceil(x / 10.0)) * 10 )\n",
    "z['employees'] = z['employees'].apply(lambda x: int(math.floor(x / 10.0)) * 10 if(x%10<5) else int(math.ceil(x / 10.0)) * 10 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Applying 90 percentiles and 10 percentiles for the lower and upper outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Calculating the 90th percentile (uq) and 10th percentile (lq)\n",
    "# duration_uq = int(z['duration'].quantile(0.90))\n",
    "# duration_lq = int(z['duration'].quantile(0.10))\n",
    "\n",
    "# dcontacts_uq = int(z['dcontacts'].quantile(0.90))\n",
    "# dcontacts_lq = int(z['dcontacts'].quantile(0.10))\n",
    "\n",
    "# pdays_uq = int(z['pdays'].quantile(0.90))\n",
    "# pdays_lq = int(z['pdays'].quantile(0.10))\n",
    "\n",
    "# pcontacts_uq = int(z['pcontacts'].quantile(0.90))\n",
    "# pcontacts_lq = int(z['pcontacts'].quantile(0.10))\n",
    "\n",
    "# evr_uq = int(z['evr'].quantile(0.90))\n",
    "# evr_lq = int(z['evr'].quantile(0.10))\n",
    "\n",
    "# cpi_uq = int(z['cpi'].quantile(0.90))\n",
    "# cpi_lq = int(z['cpi'].quantile(0.10))\n",
    "\n",
    "# cci_uq = int(z['cci'].quantile(0.90))\n",
    "# cci_lq = int(z['cci'].quantile(0.10))\n",
    "\n",
    "# euribor_uq = int(z['euribor'].quantile(0.90))\n",
    "# euribor_lq = int(z['euribor'].quantile(0.10))\n",
    "\n",
    "# employees_uq = int(z['employees'].quantile(0.90))\n",
    "# employees_lq = int(z['employees'].quantile(0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Replacing the outliers of respective variable\n",
    "# def age_outliers(x):\n",
    "#     if x['age'] < 23 and x['age'] > 0: return 23\n",
    "#     elif x['age'] > 71 and x['age'] < 78: return 71 # median\n",
    "#     elif x['age'] > 78 and x['age'] < 83: return 81\n",
    "#     elif x['age'] > 83 and x['age'] < 100: return 86\n",
    "#     else: return x['age']\n",
    "\n",
    "# z['age_outliers'] = z.apply(age_outliers, axis=1)\n",
    "\n",
    "# def duration_outliers(x):\n",
    "#     if x['duration'] < duration_lq: return duration_lq\n",
    "#     elif x['duration'] > duration_uq: return duration_uq\n",
    "#     else: return x['duration']\n",
    "\n",
    "# z['duration_outliers'] = z.apply(duration_outliers, axis=1)\n",
    "\n",
    "# def dcontacts_outliers(x):\n",
    "#     if x['dcontacts'] < dcontacts_lq: return dcontacts_lq\n",
    "#     elif x['dcontacts'] > dcontacts_uq: return dcontacts_uq\n",
    "#     else: return x['dcontacts']\n",
    "\n",
    "# z['dcontacts_outliers'] = z.apply(dcontacts_outliers, axis=1)\n",
    "\n",
    "# def pdays_outliers(x):\n",
    "#     if x['pdays'] < pdays_lq: return pdays_lq\n",
    "#     elif x['pdays'] > pdays_uq: return pdays_uq\n",
    "#     else: return x['pdays']\n",
    "\n",
    "# z['pdays_outliers'] = z.apply(pdays_outliers, axis=1)\n",
    "\n",
    "# def pcontacts_outliers(x):\n",
    "#     if x['pcontacts'] < pcontacts_lq: return pcontacts_lq\n",
    "#     elif x['pcontacts'] > pcontacts_uq: return pcontacts_uq\n",
    "#     else: return x['pcontacts']\n",
    "\n",
    "# z['pcontacts_outliers'] = z.apply(pcontacts_outliers, axis=1)\n",
    "\n",
    "# def evr_outliers(x):\n",
    "#     if x['evr'] < evr_lq: return evr_lq\n",
    "#     elif x['evr'] > evr_uq: return evr_uq\n",
    "#     else: return x['evr']\n",
    "\n",
    "# z['evr_outliers'] = z.apply(evr_outliers, axis=1)\n",
    "\n",
    "# def cpi_outliers(x):\n",
    "#     if x['cpi'] < cpi_lq: return cpi_lq\n",
    "#     elif x['cpi'] > cpi_uq: return 94.465     # Returning median \n",
    "#     else: return x['cpi']\n",
    "\n",
    "# z['cpi_outliers'] = z.apply(cpi_outliers, axis=1)\n",
    "\n",
    "# def cci_outliers(x):\n",
    "#     if x['cci'] < cci_lq: return cci_lq\n",
    "#     elif x['cci'] > cci_uq: return cci_uq\n",
    "#     else: return x['cci']\n",
    "\n",
    "# z['cci_outliers'] = z.apply(cci_outliers, axis=1)\n",
    "\n",
    "# def euribor_outliers(x):\n",
    "#     if x['euribor'] < euribor_lq: return euribor_lq\n",
    "#     elif x['euribor'] > euribor_uq: return euribor_uq # SHould I replace with mean-4.81; median-4.95 or max-5.04\n",
    "#     else: return x['euribor']\n",
    "\n",
    "# z['euribor_outliers'] = z.apply(euribor_outliers, axis=1)\n",
    "\n",
    "# def employees_outliers(x):\n",
    "#     if x['employees'] < employees_lq: return employees_lq\n",
    "#     elif x['employees'] > employees_uq: return employees_uq # What should I replace it with?\n",
    "#     # overall_mean - 5167, overall_median - 5191\n",
    "#     # outlier_mean - 5228, outlier_median - 5228\n",
    "#     # upper_bound (0.9 percentile) = 5228, lower_bound (0.1 percentile) - 4963\n",
    "#     else: return x['employees']\n",
    "\n",
    "# z['employees_outliers'] = z.apply(employees_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duration_lq = int(z['duration'].quantile(0.05))\n",
    "duration_uq = int(z['duration'].quantile(0.95))\n",
    "\n",
    "z['duration_outliers'] = z['duration'].clip_lower(duration_lq)\n",
    "z['duration_outliers'] = z['duration_outliers'].clip_upper(duration_uq)\n",
    "\n",
    "dcontacts_lq = int(z['dcontacts'].quantile(0.05))\n",
    "dcontacts_uq = int(z['dcontacts'].quantile(0.95))\n",
    "\n",
    "z['dcontacts_outliers'] = z['dcontacts'].clip_lower(dcontacts_lq)\n",
    "z['dcontacts_outliers'] = z['dcontacts_outliers'].clip_upper(dcontacts_uq)\n",
    "\n",
    "pdays_lq = int(z['pdays'].quantile(0.05))\n",
    "pdays_uq = int(z['pdays'].quantile(0.95))\n",
    "\n",
    "z['pdays_outliers'] = z['pdays'].clip_lower(pdays_lq)\n",
    "z['pdays_outliers'] = z['pdays_outliers'].clip_upper(pdays_uq)\n",
    "\n",
    "pcontacts_lq = int(z['pcontacts'].quantile(0.05))\n",
    "pcontacts_uq = int(z['pcontacts'].quantile(0.95))\n",
    "\n",
    "z['pcontacts_outliers'] = z['pcontacts'].clip_lower(pcontacts_lq)\n",
    "z['pcontacts_outliers'] = z['pcontacts_outliers'].clip_upper(pcontacts_uq)\n",
    "\n",
    "evr_lq = int(z['evr'].quantile(0.05))\n",
    "evr_uq = int(z['evr'].quantile(0.95))\n",
    "\n",
    "z['evr_outliers'] = z['evr'].clip_lower(evr_lq)\n",
    "z['evr_outliers'] = z['evr_outliers'].clip_upper(evr_uq)\n",
    "\n",
    "\n",
    "cpi_lq = int(z['cpi'].quantile(0.05))\n",
    "cpi_uq = int(z['cpi'].quantile(0.95))\n",
    "\n",
    "z['cci_outliers'] = z['cci'].clip_lower(cpi_lq)\n",
    "z['cci_outliers'] = z['cci_outliers'].clip_upper(cpi_uq)\n",
    "\n",
    "cci_lq = int(z['cci'].quantile(0.05))\n",
    "cci_uq = int(z['cci'].quantile(0.95))\n",
    "\n",
    "z['cci_outliers'] = z['cci'].clip_lower(cci_lq)\n",
    "z['cci_outliers'] = z['cci_outliers'].clip_upper(cci_uq)\n",
    "\n",
    "euribor_lq = int(z['euribor'].quantile(0.05))\n",
    "euribor_uq = int(z['euribor'].quantile(0.95))\n",
    "\n",
    "z['euribor_outliers'] = z['euribor'].clip_lower(euribor_lq)\n",
    "z['euribor_outliers'] = z['euribor_outliers'].clip_upper(euribor_uq)\n",
    "\n",
    "employees_lq = int(z['employees'].quantile(0.05))\n",
    "employees_uq = int(z['employees'].quantile(0.95))\n",
    "\n",
    "z['employees_outliers'] = z['employees'].clip_lower(employees_lq)\n",
    "z['employees_outliers'] = z['employees_outliers'].clip_upper(employees_uq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Apply Logarithmic transformations to invalid outliers (Not to the outliers but to all the entries in the numeric columns). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new dataframe to apply logarithm transformations.\n",
    "From all the numerical columns, logarithmic transformations can be applied to only a few since others have '0' and negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z.astype(bool).sum(axis=0)      # Count of zeros in a columns\n",
    "# z[z<0].count()                  # Count of negative values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = ['age','dcontacts','cpi','euribor','employees','duration_outliers','dcontacts_outliers','pdays_outliers','euribor_outliers','employees_outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_log = z.copy(deep=True)\n",
    "for n in num:\n",
    "    z_log[n] = np.log(z_log[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Data Rescaling</b>\n",
    "\n",
    "Preprocessed data may contain attributes with a mixtures of scales for various quantities such as dollars, kilograms \n",
    "and sales volume.\n",
    "\n",
    "Many machine learning methods expect or are more effective if the data attributes have the same scale. \n",
    "Two popular data scaling methods are normalization and standardization.\n",
    "\n",
    "Data Normalization\n",
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, \n",
    "such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "Data Standardization\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a \n",
    "standard deviation of one (unit variance).\n",
    "\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "Which Method To Use\n",
    "It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them. \n",
    "If often can, but not always.\n",
    "\n",
    "A good tip is to create rescaled copies of your dataset and race them against each other using your test harness \n",
    "and a handful of algorithms you want to spot check. This can quickly highlight the benefits (or lack there of) of \n",
    "rescaling your data with given models, and which rescaling method may be worthy of further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Standardizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZATION\n",
    "The process of converting all input values into a common scale usually between 0 and 1. \n",
    "It is not always a good idea to normalize the data since we might lose the minimum and maximum values.\n",
    "But most often it is a good idea.\n",
    "Advt: ML algorithms such as Linear Regression and SVM perform faster on normalized data.\n",
    "\n",
    "STANDARDIZATION\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a \n",
    "standard deviation of one (unit variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_normalized = z.copy(deep = True)   # All changes applied\n",
    "z_standardized = z.copy(deep = True) # All changes applied\n",
    "\n",
    "df_duration_yes = z.copy(deep=True)\n",
    "df_duration_no = z.copy(deep=True)\n",
    "\n",
    "df_duration_yes_normalized = df_duration_yes.copy(deep = True)\n",
    "df_duration_yes_standardized = df_duration_yes.copy(deep = True)\n",
    "\n",
    "df_duration_no_normalized = df_duration_no.copy(deep = True)\n",
    "df_duration_no_standardized = df_duration_no.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical = ['age','duration','dcontacts','pdays','pcontacts','evr','cpi','cci','euribor','employees','duration_outliers','dcontacts_outliers','pdays_outliers','pcontacts_outliers','evr_outliers','cci_outliers','euribor_outliers','employees_outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataframe in (z_normalized, df_duration_yes_normalized, df_duration_no_normalized):\n",
    "    for n in numerical:\n",
    "        col = dataframe[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.MinMaxScaler()).fit_transform(col)\n",
    "        dataframe[n+'_normalized'] = pd.DataFrame(col_transformed)\n",
    "\n",
    "for dataframe in (z_standardized, df_duration_yes_standardized, df_duration_no_standardized):\n",
    "    for n in numerical:\n",
    "        col = dataframe[[n]].values.astype(float)\n",
    "        col_transformed = (preprocessing.StandardScaler()).fit_transform(col)\n",
    "        dataframe[n+'_standardized'] = pd.DataFrame(col_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete 'duration' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_duration_no_standardized.drop('duration',axis=1, inplace=True) #axis = 1 deletes column; axis = 0 delets rows\n",
    "# df_duration_no_normalized.drop('duration',axis=1, inplace=True)\n",
    "# df_duration_no.drop('duration',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duration_no_normalized.drop('duration',axis=1, inplace=True)\n",
    "df_duration_no_standardized.drop('duration',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for d in (z, df, z_normalized, z_standardized, df_duration_yes, df_duration_no, df_duration_yes_normalized, \n",
    "#                  df_duration_yes_standardized, df_duration_no_normalized, df_duration_no_standardized):\n",
    "#     d = pd.get_dummies(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = pd.get_dummies(z)\n",
    "df = pd.get_dummies(df)\n",
    "z_normalized = pd.get_dummies(z_normalized)\n",
    "z_standardized = pd.get_dummies(z_standardized)\n",
    "df_duration_yes = pd.get_dummies(df_duration_yes)\n",
    "df_duration_no = pd.get_dummies(df_duration_no)\n",
    "df_duration_yes_normalized = pd.get_dummies(df_duration_yes_normalized)\n",
    "df_duration_yes_standardized = pd.get_dummies(df_duration_yes_standardized)\n",
    "df_duration_no_normalized = pd.get_dummies(df_duration_no_normalized)\n",
    "df_duration_no_standardized = pd.get_dummies(df_duration_no_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job', 'marital', 'education', 'default', 'housing', 'personal',\n",
       "       'contact_type', 'month', 'day', 'poutcome', 'y'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of all the categorical variables in a dataframe.\n",
    "test.select_dtypes(include=['O']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u> Note </u>:\n",
    "Using multiple conditions in Lambda functions: lambda x: x*10 if x<20 else (x**2 if x<4 else x+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Warning </u> : More about 'SettingWithCopyWarning' warning.\n",
    "https://www.dataquest.io/blog/settingwithcopywarning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
